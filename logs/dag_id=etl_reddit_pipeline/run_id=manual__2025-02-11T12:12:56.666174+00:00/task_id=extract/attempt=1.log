[2025-02-11T12:12:58.302+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-11T12:12:58.318+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.extract manual__2025-02-11T12:12:56.666174+00:00 [queued]>
[2025-02-11T12:12:58.324+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.extract manual__2025-02-11T12:12:56.666174+00:00 [queued]>
[2025-02-11T12:12:58.325+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 1
[2025-02-11T12:12:58.332+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): extract> on 2025-02-11 12:12:56.666174+00:00
[2025-02-11T12:12:58.337+0000] {standard_task_runner.py:72} INFO - Started process 80 to run task
[2025-02-11T12:12:58.340+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'extract', 'manual__2025-02-11T12:12:56.666174+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmpl4ph4xpx']
[2025-02-11T12:12:58.341+0000] {standard_task_runner.py:105} INFO - Job 23: Subtask extract
[2025-02-11T12:12:58.389+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_reddit_pipeline.extract manual__2025-02-11T12:12:56.666174+00:00 [running]> on host a496235afc73
[2025-02-11T12:12:58.463+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Iris' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='extract' AIRFLOW_CTX_EXECUTION_DATE='2025-02-11T12:12:56.666174+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-02-11T12:12:56.666174+00:00'
[2025-02-11T12:12:58.464+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-11T12:12:58.496+0000] {logging_mixin.py:190} INFO - Connected to Reddit
[2025-02-11T12:12:59.380+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '[Tomasz Tunguz](https://www.linkedin.com/in/tomasztunguz/) recently outlined three big shifts in 2025:   \n  \n1Ô∏è‚É£ The Great Consolidation ‚Äì "Don\'t sell me another data tool" - Teams are tired of juggling 20+ tools. They want a simpler, more unified data stack.  \n  \n2Ô∏è‚É£ The Return of Scale-Up Computing ‚Äì The pendulum is swinging back to powerful single machines, optimized for Python-first workflows.  \n  \n3Ô∏è‚É£ Agentic Data ‚Äì AI isn‚Äôt just analyzing data anymore. It‚Äôs starting to manage and optimize it in real time.\n\nQuite an interesting read- [https://tomtunguz.com/top-themes-in-data-2025/](https://tomtunguz.com/top-themes-in-data-2025/)', 'author_fullname': 't2_z3snwqqe9', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Big shifts in the data world in 2025', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1im7dak', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 203, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 203, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739197795.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p><a href="https://www.linkedin.com/in/tomasztunguz/">Tomasz Tunguz</a> recently outlined three big shifts in 2025:   </p>\n\n<p>1Ô∏è‚É£ The Great Consolidation ‚Äì &quot;Don&#39;t sell me another data tool&quot; - Teams are tired of juggling 20+ tools. They want a simpler, more unified data stack.  </p>\n\n<p>2Ô∏è‚É£ The Return of Scale-Up Computing ‚Äì The pendulum is swinging back to powerful single machines, optimized for Python-first workflows.  </p>\n\n<p>3Ô∏è‚É£ Agentic Data ‚Äì AI isn‚Äôt just analyzing data anymore. It‚Äôs starting to manage and optimize it in real time.</p>\n\n<p>Quite an interesting read- <a href="https://tomtunguz.com/top-themes-in-data-2025/">https://tomtunguz.com/top-themes-in-data-2025/</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1im7dak', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Better-Department662'), 'discussion_type': None, 'num_comments': 45, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1im7dak/big_shifts_in_the_data_world_in_2025/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1im7dak/big_shifts_in_the_data_world_in_2025/', 'subreddit_subscribers': 254039, 'created_utc': 1739197795.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.380+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Just in case anyone else is thinking about the switch‚Ä¶\n\nI was initially a bit apprehensive of using Dagster, mainly because every comparison of Airflow and Dagster says that because the concepts behind it are ‚Äúasset based‚Äù rather than ‚Äúworkflow based‚Äù, it‚Äôs a steeper learning curve.\n\nSo yes, you‚Äôll be used to thinking about orchestration as workflow tasks, and yes you will make the mistake of making op jobs, things getting a bit weird, then having to refactor to use assets‚Ä¶ but once your mind shifts, writing data pipelines is honestly a dream.\n\nWhere I think it will really shine as it matures is when you have very large projects that are several years old. The fact that every dataset you create is tied to a specific bit of transformation code in such an obvious way, you‚Äôre not having to map in your mind through lots of jobs what‚Äôs happening.\n\nContext switching between data lineage in snowflake/Databricks/DBT and your Dagster code also feels seamless, because it‚Äôs all just the same flow.\n\nHope this helps üëç', 'author_fullname': 't2_lodwnfe3v', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Myth: Dagster is harder than Airflow', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imjtro', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': 'transparent', 'subreddit_type': 'public', 'ups': 74, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': '980947cc-e787-11ed-87e3-ae81ee052dfe', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 74, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739228422.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Just in case anyone else is thinking about the switch‚Ä¶</p>\n\n<p>I was initially a bit apprehensive of using Dagster, mainly because every comparison of Airflow and Dagster says that because the concepts behind it are ‚Äúasset based‚Äù rather than ‚Äúworkflow based‚Äù, it‚Äôs a steeper learning curve.</p>\n\n<p>So yes, you‚Äôll be used to thinking about orchestration as workflow tasks, and yes you will make the mistake of making op jobs, things getting a bit weird, then having to refactor to use assets‚Ä¶ but once your mind shifts, writing data pipelines is honestly a dream.</p>\n\n<p>Where I think it will really shine as it matures is when you have very large projects that are several years old. The fact that every dataset you create is tied to a specific bit of transformation code in such an obvious way, you‚Äôre not having to map in your mind through lots of jobs what‚Äôs happening.</p>\n\n<p>Context switching between data lineage in snowflake/Databricks/DBT and your Dagster code also feels seamless, because it‚Äôs all just the same flow.</p>\n\n<p>Hope this helps üëç</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Principal Data Engineer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1imjtro', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='General-Parsnip3138'), 'discussion_type': None, 'num_comments': 16, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1imjtro/myth_dagster_is_harder_than_airflow/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imjtro/myth_dagster_is_harder_than_airflow/', 'subreddit_subscribers': 254039, 'created_utc': 1739228422.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.381+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I feel like there is so much potential to move away from massive data warehouses to purely file based storage in iceberg and in process compute like duckdb. I don‚Äôt personally know anyone doing that nor have I heard experts talking about using this pattern. \n\nIt would simplify architecture, reduce vendor locking, and reduce cost of storing and loading data. \n\nFor medium workloads, like a few TB data storage a year, something like this is ideal IMO. Is it a viable long term strategy to build your data warehouse around these tools?\n\n', 'author_fullname': 't2_jt2s1', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'When is duckdb and iceberg enough?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1im5kgl', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.97, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 55, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 55, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739192491.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I feel like there is so much potential to move away from massive data warehouses to purely file based storage in iceberg and in process compute like duckdb. I don‚Äôt personally know anyone doing that nor have I heard experts talking about using this pattern. </p>\n\n<p>It would simplify architecture, reduce vendor locking, and reduce cost of storing and loading data. </p>\n\n<p>For medium workloads, like a few TB data storage a year, something like this is ideal IMO. Is it a viable long term strategy to build your data warehouse around these tools?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1im5kgl', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='haragoshi'), 'discussion_type': None, 'num_comments': 43, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1im5kgl/when_is_duckdb_and_iceberg_enough/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1im5kgl/when_is_duckdb_and_iceberg_enough/', 'subreddit_subscribers': 254039, 'created_utc': 1739192491.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.381+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '', 'author_fullname': 't2_vgkgnq8w', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data Analytics with PostgreSQL: The Ultimate Guide', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 81, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1im8olq', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.91, 'author_flair_background_color': None, 'ups': 50, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 50, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/BIyTaOEuxx-lgXieuV0qAA2UiUYFcIoiQsrhXa8Ky4w.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1739201287.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'blog.bemi.io', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://blog.bemi.io/analytics-with-***ql/', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/4Pb3AzOTe-biZ8b66AoSboIEPYHfel1IybCP7JrX6bU.jpg?auto=webp&s=6d21601a5e6fe9e17ea5aa82293bf13a9a7893b4', 'width': 3336, 'height': 1943}, 'resolutions': [{'url': 'https://external-preview.redd.it/4Pb3AzOTe-biZ8b66AoSboIEPYHfel1IybCP7JrX6bU.jpg?width=108&crop=smart&auto=webp&s=f551d75f9f8bd5b6b7dcfb11a93886079766b611', 'width': 108, 'height': 62}, {'url': 'https://external-preview.redd.it/4Pb3AzOTe-biZ8b66AoSboIEPYHfel1IybCP7JrX6bU.jpg?width=216&crop=smart&auto=webp&s=e15e9890451ed55819c7ef73f319bb1ed9ca8b6e', 'width': 216, 'height': 125}, {'url': 'https://external-preview.redd.it/4Pb3AzOTe-biZ8b66AoSboIEPYHfel1IybCP7JrX6bU.jpg?width=320&crop=smart&auto=webp&s=69771678d396befad70099e08451474da9d9b0fe', 'width': 320, 'height': 186}, {'url': 'https://external-preview.redd.it/4Pb3AzOTe-biZ8b66AoSboIEPYHfel1IybCP7JrX6bU.jpg?width=640&crop=smart&auto=webp&s=a76819f70aee9a61345f4a94774b44a8247d1714', 'width': 640, 'height': 372}, {'url': 'https://external-preview.redd.it/4Pb3AzOTe-biZ8b66AoSboIEPYHfel1IybCP7JrX6bU.jpg?width=960&crop=smart&auto=webp&s=16c8bc791d79c3edda2f23166f133380dfc9575b', 'width': 960, 'height': 559}, {'url': 'https://external-preview.redd.it/4Pb3AzOTe-biZ8b66AoSboIEPYHfel1IybCP7JrX6bU.jpg?width=1080&crop=smart&auto=webp&s=c1bf82b8776511f65fe1d247de5017354fbc887c', 'width': 1080, 'height': 629}], 'variants': {}, 'id': '_zM-_xVqdka_Rsgod9INnTfAGJjDsZQFl4YtXoh6MrU'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1im8olq', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='arjunloll'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1im8olq/data_analytics_with_***ql_the_ultimate_guide/', 'stickied': False, 'url': 'https://blog.bemi.io/analytics-with-***ql/', 'subreddit_subscribers': 254039, 'created_utc': 1739201287.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.383+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I work at a startup stock exchange. I am doing a project to set up an analytics data warehouse. We already have an application database in *** with neatly structured data, but we want to move away from using that database for everything.\n\nI proposed this idea myself and I'm really keen on working on it and developing myself further in this field. I just finished my masters statistics a year ago and have done a lot of sql and python programming, but nothing like this.\n\nWe have a lot of order and transaction data per day, but nothing crazy yet (since we're still small) to justify using spark. If everything goes well our daily data will increase quickly though so there is a need to keep an eye on the future.\n\nAfter doing some research it seems like the best way to go is a snowflake data-warehouse with dbt ELT pipelines syncing the new data every night during market close to the warehouse and transforming it to a metrics layer that is connected to a BI tool like metabase. I'm not sure if i need a separate orchestrator, but dragster seems like the best one out there, and to make it future proof with might be good to already include it in the infrastructure.\n\nWe run everything in AWS so it will probably get deployed to our cluster there. I've looked into the AWS native solutions like redshift, glue, athena, etc, but I rarely read very good things about them.\n\nAm I on the right track? I would appreciate some help. The idea is to start with something small and simple that scales well for easy expansion dependent on our growth.\n\nI'm very excited for this project, even a few sentences would mean the world to me! :)\n\n", 'author_fullname': 't2_14wthz', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Is snowflake + dbt + dragster the way to go?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1im6qx1', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.87, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 40, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 40, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739196067.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I work at a startup stock exchange. I am doing a project to set up an analytics data warehouse. We already have an application database in *** with neatly structured data, but we want to move away from using that database for everything.</p>\n\n<p>I proposed this idea myself and I&#39;m really keen on working on it and developing myself further in this field. I just finished my masters statistics a year ago and have done a lot of sql and python programming, but nothing like this.</p>\n\n<p>We have a lot of order and transaction data per day, but nothing crazy yet (since we&#39;re still small) to justify using spark. If everything goes well our daily data will increase quickly though so there is a need to keep an eye on the future.</p>\n\n<p>After doing some research it seems like the best way to go is a snowflake data-warehouse with dbt ELT pipelines syncing the new data every night during market close to the warehouse and transforming it to a metrics layer that is connected to a BI tool like metabase. I&#39;m not sure if i need a separate orchestrator, but dragster seems like the best one out there, and to make it future proof with might be good to already include it in the infrastructure.</p>\n\n<p>We run everything in AWS so it will probably get deployed to our cluster there. I&#39;ve looked into the AWS native solutions like redshift, glue, athena, etc, but I rarely read very good things about them.</p>\n\n<p>Am I on the right track? I would appreciate some help. The idea is to start with something small and simple that scales well for easy expansion dependent on our growth.</p>\n\n<p>I&#39;m very excited for this project, even a few sentences would mean the world to me! :)</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1im6qx1', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Jobdriaan'), 'discussion_type': None, 'num_comments': 56, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1im6qx1/is_snowflake_dbt_dragster_the_way_to_go/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1im6qx1/is_snowflake_dbt_dragster_the_way_to_go/', 'subreddit_subscribers': 254039, 'created_utc': 1739196067.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.384+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hey everyone,\n\nI‚Äôm working on a data pipeline, and I‚Äôve been wrestling with whether the Medallion architecture is worth it in simpler use cases. I‚Äôm storing files grouped by categories ‚Äî let‚Äôs say, dogs by the parks they‚Äôre in. We‚Äôre ingesting this raw data as events, so there could be many dogs in each park, from various sources.\n\nHere‚Äôs the dilemma:\n\nThe Medallion architecture recommends scrubbing and normalizing the data into a ‚Äòsilver‚Äô layer before creating the final ‚Äògold‚Äô layer. But in my case, the end goal is a denormalized view: dogs grouped by park and identified by dog ID, which is what we need for querying. That's a simple group by. So this presents me with two choices:\n\n**1:**  \nSkip the normalizing step, and go straight from raw to a single denormalized view (essentially the ‚Äògold‚Äô table). This avoids the need to create intermediate ‚Äòsilver‚Äô tables and feels more efficient, as Spark doesn‚Äôt need to perform joins to rebuild the final view.\n\n**2:**  \nFollow the Medallion architecture by normalizing the data first‚Äîsplitting it into tables like ‚Äúparks‚Äù and ‚Äúdogs.‚Äù This performs worse because Spark has to join these tables later (e.g., broadcast joins, because there's not that many parks), and it seems like Spark struggles more with joins compared to simple filter operations, and, you end up building a denormalized ‚Äògold‚Äô view anyway, which feels like extra compute for no real benefit.\n\nSo, in cases like this where the data is fairly simple, does it make sense to abandon the Medallion architecture altogether? Are there hidden benefits to sticking with it even when the denormalized result is all you need? The only value I can see in it is consistency (but possibly over-engineered) series of tables that become strangely reminiscent of what you usually see in any Postgres deployment.\n\nCurious to hear your thoughts or approaches for similar situations!\n\nThanks in advance.", 'author_fullname': 't2_k20bsxgz0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Is Medallion Architecture Overkill for Simple Use Cases? Seeking Advice', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imicxx', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 17, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 17, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1739225540.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739224691.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey everyone,</p>\n\n<p>I‚Äôm working on a data pipeline, and I‚Äôve been wrestling with whether the Medallion architecture is worth it in simpler use cases. I‚Äôm storing files grouped by categories ‚Äî let‚Äôs say, dogs by the parks they‚Äôre in. We‚Äôre ingesting this raw data as events, so there could be many dogs in each park, from various sources.</p>\n\n<p>Here‚Äôs the dilemma:</p>\n\n<p>The Medallion architecture recommends scrubbing and normalizing the data into a ‚Äòsilver‚Äô layer before creating the final ‚Äògold‚Äô layer. But in my case, the end goal is a denormalized view: dogs grouped by park and identified by dog ID, which is what we need for querying. That&#39;s a simple group by. So this presents me with two choices:</p>\n\n<p><strong>1:</strong><br/>\nSkip the normalizing step, and go straight from raw to a single denormalized view (essentially the ‚Äògold‚Äô table). This avoids the need to create intermediate ‚Äòsilver‚Äô tables and feels more efficient, as Spark doesn‚Äôt need to perform joins to rebuild the final view.</p>\n\n<p><strong>2:</strong><br/>\nFollow the Medallion architecture by normalizing the data first‚Äîsplitting it into tables like ‚Äúparks‚Äù and ‚Äúdogs.‚Äù This performs worse because Spark has to join these tables later (e.g., broadcast joins, because there&#39;s not that many parks), and it seems like Spark struggles more with joins compared to simple filter operations, and, you end up building a denormalized ‚Äògold‚Äô view anyway, which feels like extra compute for no real benefit.</p>\n\n<p>So, in cases like this where the data is fairly simple, does it make sense to abandon the Medallion architecture altogether? Are there hidden benefits to sticking with it even when the denormalized result is all you need? The only value I can see in it is consistency (but possibly over-engineered) series of tables that become strangely reminiscent of what you usually see in any Postgres deployment.</p>\n\n<p>Curious to hear your thoughts or approaches for similar situations!</p>\n\n<p>Thanks in advance.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1imicxx', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Certain_Leader9946'), 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imicxx/is_medallion_architecture_overkill_for_simple_use/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imicxx/is_medallion_architecture_overkill_for_simple_use/', 'subreddit_subscribers': 254039, 'created_utc': 1739224691.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.384+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'As the title suggests, I have been offered a position as a Fullstack Intern. However, in the future, I don‚Äôt think I want to continue as a fullstack developer; instead, I am interested in becoming a data engineer. That said, this offer is appealing because, as a fullstack intern, I will gain exposure to the environment (such as deployment processes), which I believe is similar to aspects of data engineering. Additionally, this internship will count as professional experience on my CV. Should I accept the offer?\n\nFYI: I am a 6th-semester student in computer science.', 'author_fullname': 't2_98k4mjlj', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Offered as Fullstack Intern but data engineer job is my dream job', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1im57q6', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 8, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 8, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739191300.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>As the title suggests, I have been offered a position as a Fullstack Intern. However, in the future, I don‚Äôt think I want to continue as a fullstack developer; instead, I am interested in becoming a data engineer. That said, this offer is appealing because, as a fullstack intern, I will gain exposure to the environment (such as deployment processes), which I believe is similar to aspects of data engineering. Additionally, this internship will count as professional experience on my CV. Should I accept the offer?</p>\n\n<p>FYI: I am a 6th-semester student in computer science.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1im57q6', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='choco_late_666'), 'discussion_type': None, 'num_comments': 10, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1im57q6/offered_as_fullstack_intern_but_data_engineer_job/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1im57q6/offered_as_fullstack_intern_but_data_engineer_job/', 'subreddit_subscribers': 254039, 'created_utc': 1739191300.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.384+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi, I am currently a data engineer in a big company with 1.5 yoe that doesn't use any cloud technologies like AWS, Azure or GCP but prefers to do everything in house on premises with Hive, HDFS, Spark clusters, scheduling cron jobs for ETL, pipelines and using normal logging for debugging where things end up going wrong. It's an annoying job and I want to upskill before leaving and joining another job. I have a CS degree from a reputed college and I'm good with CS concepts as well but idk anything related to JS or front end technologies besides API building. I also know how to code in Java and C++, have learned ML, Stats, cloud technologies, security concepts in my college years.\n\nCurrently I work in python, mongodb, spark, analysis libraries and that's about it. In order to switch I have planned the following but I wanted someone to validate or invalidate my path and help me out with what I should be doing instead:\n\n1. Python DSA leetcode\n2. SQL leetcode\n3. Deeplearning.ai data engineering course with Joe Reis for fundamentals\n4. DP203 or AWS equivalent (not sure about this yet)\n\nWhat do you guys think? Am I going the right path?", 'author_fullname': 't2_15gkof', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Studying for a job switch with basically no tech stack', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imr92s', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.74, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739251123.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi, I am currently a data engineer in a big company with 1.5 yoe that doesn&#39;t use any cloud technologies like AWS, Azure or GCP but prefers to do everything in house on premises with Hive, HDFS, Spark clusters, scheduling cron jobs for ETL, pipelines and using normal logging for debugging where things end up going wrong. It&#39;s an annoying job and I want to upskill before leaving and joining another job. I have a CS degree from a reputed college and I&#39;m good with CS concepts as well but idk anything related to JS or front end technologies besides API building. I also know how to code in Java and C++, have learned ML, Stats, cloud technologies, security concepts in my college years.</p>\n\n<p>Currently I work in python, mongodb, spark, analysis libraries and that&#39;s about it. In order to switch I have planned the following but I wanted someone to validate or invalidate my path and help me out with what I should be doing instead:</p>\n\n<ol>\n<li>Python DSA leetcode</li>\n<li>SQL leetcode</li>\n<li>Deeplearning.ai data engineering course with Joe Reis for fundamentals</li>\n<li>DP203 or AWS equivalent (not sure about this yet)</li>\n</ol>\n\n<p>What do you guys think? Am I going the right path?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1imr92s', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='depressed_happiness'), 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imr92s/studying_for_a_job_switch_with_basically_no_tech/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imr92s/studying_for_a_job_switch_with_basically_no_tech/', 'subreddit_subscribers': 254039, 'created_utc': 1739251123.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.384+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "**Background**: I got Hired as the only data warehouse engineer role in the BI team of my department; they told me I would be involved in a big cloud migration project and get in touch with Azure data infrastructure. Then, I was informed that I might no longer get involved right after being onboarded. My manager said I might spend a year or two implementing on-premise solutions for the department instead.\n\n**My question**: Should I stay until the project finishes and find a better opportunity or find another right away? Due to the strict privacy restrictions, my team can't even have read access to the production database directly, so I strongly doubt the possibility of building a data warehouse.\n\n**Edit**: I am a new graduate with 1.5 yoe and built a small DW for my previous employer, I expected a project to learn the Enterprise level of DW as the start of my DE career\n\nAny thoughts are welcomed!", 'author_fullname': 't2_ehg2vux7', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Should I Stay or Leave for better future career', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imdg9x', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.69, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1739213758.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739212846.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p><strong>Background</strong>: I got Hired as the only data warehouse engineer role in the BI team of my department; they told me I would be involved in a big cloud migration project and get in touch with Azure data infrastructure. Then, I was informed that I might no longer get involved right after being onboarded. My manager said I might spend a year or two implementing on-premise solutions for the department instead.</p>\n\n<p><strong>My question</strong>: Should I stay until the project finishes and find a better opportunity or find another right away? Due to the strict privacy restrictions, my team can&#39;t even have read access to the production database directly, so I strongly doubt the possibility of building a data warehouse.</p>\n\n<p><strong>Edit</strong>: I am a new graduate with 1.5 yoe and built a small DW for my previous employer, I expected a project to learn the Enterprise level of DW as the start of my DE career</p>\n\n<p>Any thoughts are welcomed!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imdg9x', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='JowwLee'), 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imdg9x/should_i_stay_or_leave_for_better_future_career/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imdg9x/should_i_stay_or_leave_for_better_future_career/', 'subreddit_subscribers': 254039, 'created_utc': 1739212846.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.385+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi All,\n\nAnyone have experience ingesting big amount of data into search indexes? what were the biggest challenges and how did you solve it ?', 'author_fullname': 't2_tytjjyk0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What is your biggest pain points ingesting big data into search indexes ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1im57rl', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.82, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739191304.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi All,</p>\n\n<p>Anyone have experience ingesting big amount of data into search indexes? what were the biggest challenges and how did you solve it ?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1im57rl', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Sarcinismo'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1im57rl/what_is_your_biggest_pain_points_ingesting_big/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1im57rl/what_is_your_biggest_pain_points_ingesting_big/', 'subreddit_subscribers': 254039, 'created_utc': 1739191304.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.385+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I‚Äôve read that during coding interviews, you need to verify your code and that doesn‚Äôt mean hitting run. Does that mean you shouldn‚Äôt run your code with different sample inputs? How is it different from explaining your code line by line? Are there any good videos that showcase this?\n\nAlso when testing code in interviews, do you actually write unit tests? or do you just pass example test cases directly into your function?', 'author_fullname': 't2_59ggcmrq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data Engineering coding interviews: what does verifying code mean?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imjl6l', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.8, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739227790.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I‚Äôve read that during coding interviews, you need to verify your code and that doesn‚Äôt mean hitting run. Does that mean you shouldn‚Äôt run your code with different sample inputs? How is it different from explaining your code line by line? Are there any good videos that showcase this?</p>\n\n<p>Also when testing code in interviews, do you actually write unit tests? or do you just pass example test cases directly into your function?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imjl6l', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='jinbe-san'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imjl6l/data_engineering_coding_interviews_what_does/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imjl6l/data_engineering_coding_interviews_what_does/', 'subreddit_subscribers': 254039, 'created_utc': 1739227790.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.385+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hey folks, I'm working with my friend u/buremba on [UniverSQL](https://github.com/buremba/universql), a tool that converts Snowflake queries to DuckDB and runs them on whichever environment you're running on (e.g. your local desktop or EC2 instances).  We're finishing up a release that allows you to run your Snowflake ELT queries on duckdb so you can transform data in local duckdb and load it into Snowflake without using Snowflake compute.\n\nAs a result, we'd like to run some ETL-focused benchmarks to see what type/size EC2 instances are comparable to Snowflake in performance/cost.  However, I'm struggling to find any data sets with standard queries like TPC/Clickbench that focus on ETL.\n\nDoes anyone know any they could point us to?  Really appreciate it!", 'author_fullname': 't2_4l9w2jyf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'ETL Benchmark Data Set + Queries...does it exist?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1img4h9', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.78, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1739220910.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739219198.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey folks, I&#39;m working with my friend <a href="/u/buremba">u/buremba</a> on <a href="https://github.com/buremba/universql">UniverSQL</a>, a tool that converts Snowflake queries to DuckDB and runs them on whichever environment you&#39;re running on (e.g. your local desktop or EC2 instances).  We&#39;re finishing up a release that allows you to run your Snowflake ELT queries on duckdb so you can transform data in local duckdb and load it into Snowflake without using Snowflake compute.</p>\n\n<p>As a result, we&#39;d like to run some ETL-focused benchmarks to see what type/size EC2 instances are comparable to Snowflake in performance/cost.  However, I&#39;m struggling to find any data sets with standard queries like TPC/Clickbench that focus on ETL.</p>\n\n<p>Does anyone know any they could point us to?  Really appreciate it!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/vfmaGOoQZsdAtXaE7OSaAUSK764Ier1_SiXSH1OAbE8.jpg?auto=webp&s=3759300faedee676583f855d3308d4e8e937c080', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/vfmaGOoQZsdAtXaE7OSaAUSK764Ier1_SiXSH1OAbE8.jpg?width=108&crop=smart&auto=webp&s=6fffd8ef0918973994df6850ef54a339941be4a9', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/vfmaGOoQZsdAtXaE7OSaAUSK764Ier1_SiXSH1OAbE8.jpg?width=216&crop=smart&auto=webp&s=1def9e170a2fd7653784cf5e4b32b140a854e363', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/vfmaGOoQZsdAtXaE7OSaAUSK764Ier1_SiXSH1OAbE8.jpg?width=320&crop=smart&auto=webp&s=79613c616b21ede2188883037a13838b8ba8dd06', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/vfmaGOoQZsdAtXaE7OSaAUSK764Ier1_SiXSH1OAbE8.jpg?width=640&crop=smart&auto=webp&s=0a687e5c497f0d697057aabb878dac6cd817a989', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/vfmaGOoQZsdAtXaE7OSaAUSK764Ier1_SiXSH1OAbE8.jpg?width=960&crop=smart&auto=webp&s=f2c1d365d2fc797dc721df7f6e6c76295036cf64', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/vfmaGOoQZsdAtXaE7OSaAUSK764Ier1_SiXSH1OAbE8.jpg?width=1080&crop=smart&auto=webp&s=49e6401d68eb2520bb2346db35055415f317ae08', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'kCsTzNeI2MgvoArPaKb6zeEhedTyHpvAUE14slUk-WU'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1img4h9', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='ryan_with_a_why'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1img4h9/etl_benchmark_data_set_queriesdoes_it_exist/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1img4h9/etl_benchmark_data_set_queriesdoes_it_exist/', 'subreddit_subscribers': 254039, 'created_utc': 1739219198.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.386+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'm learning to become a beginner data engineer.\n\nShould I focus on exploring as many new things as possible in SQL and Python, and then just Google things as needed on the job? Or is it better to concentrate on a few core concepts and truly master them, so I can be more agile and fluent when using them in real-world scenarios?\n\nAlso, what do you consider to be the most basic and important skills for a junior data engineer to focus on?\n\nWould love to hear advice from experienced data engineers! üòä", 'author_fullname': 't2_bvqqxner', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Best Approach to Learning SQL & Python for Data Engineering?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1imvi2p', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739269338.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m learning to become a beginner data engineer.</p>\n\n<p>Should I focus on exploring as many new things as possible in SQL and Python, and then just Google things as needed on the job? Or is it better to concentrate on a few core concepts and truly master them, so I can be more agile and fluent when using them in real-world scenarios?</p>\n\n<p>Also, what do you consider to be the most basic and important skills for a junior data engineer to focus on?</p>\n\n<p>Would love to hear advice from experienced data engineers! üòä</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imvi2p', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Durszlakovvy'), 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imvi2p/best_approach_to_learning_sql_python_for_data/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imvi2p/best_approach_to_learning_sql_python_for_data/', 'subreddit_subscribers': 254039, 'created_utc': 1739269338.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.386+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'm learning various concepts involved in airflow for work. I'm having hard time making a case for why I should chose one over the other in a use case. I can see both serving my purpose. Based on your experience, which one would you use for which type of task?", 'author_fullname': 't2_hqiwxblm', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'When to use dynamic dags vs dynamic tasks?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imkdor', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739229897.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m learning various concepts involved in airflow for work. I&#39;m having hard time making a case for why I should chose one over the other in a use case. I can see both serving my purpose. Based on your experience, which one would you use for which type of task?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1imkdor', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Traditional_Reason59'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imkdor/when_to_use_dynamic_dags_vs_dynamic_tasks/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imkdor/when_to_use_dynamic_dags_vs_dynamic_tasks/', 'subreddit_subscribers': 254039, 'created_utc': 1739229897.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.386+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi All,\n\nCurious to hear if you worked on projects that required building ETL for big unstructured data.  \n  \n1. What were your biggest pain points?  \n2. Any tools you would recommend to use? ', 'author_fullname': 't2_tytjjyk0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to scale ETL for  big unstructured data ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imv4t4', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739267667.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi All,</p>\n\n<p>Curious to hear if you worked on projects that required building ETL for big unstructured data.  </p>\n\n<ol>\n<li>What were your biggest pain points?<br/></li>\n<li>Any tools you would recommend to use? </li>\n</ol>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1imv4t4', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Sarcinismo'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imv4t4/how_to_scale_etl_for_big_unstructured_data/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imv4t4/how_to_scale_etl_for_big_unstructured_data/', 'subreddit_subscribers': 254039, 'created_utc': 1739267667.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.386+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hello, apologies in advance if this isn‚Äôt the appropriate group to post this in. I‚Äôm working as a data engineer for a gaming company in Berlin. I don‚Äôt have a proper team. Our CTO wrote a custom data pipeline in C sharp years ago.  I was expected to take responsibility maintaining, improving, optimising the data pipeline, integrate a couple APIs, ingress data from marketing tools and ad network as well as reporting on looker studio for BI. I managed to do this pretty quickly after joining and am doing pretty well. However , since I do not have a team there is no senior to look up to, no team to discuss ideas with, no plans to\nintegrate data tools like snowflake or airflow , I feel\n1. There is no one I can interact with who understands my work at my workplace \n2. I am unable to expand practical knowledge in data engineering since we not introducing any new tools \n3. Progression is unclear e.g what qualifies me for a senior data engineer role at the studio\n3. It‚Äôs pretty quiet and sad at work without a team.\n\nFor those date engineers who are a solo person team, how do you cope with all this ? Is it advisable to start looking for a new job ? \n\nI have started learning airflow and snowflake on my own as it might help me switch jobs later on ', 'author_fullname': 't2_ay5k3kd3', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Need advice from solo/single member team Data Engineers', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imicne', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.57, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739224669.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello, apologies in advance if this isn‚Äôt the appropriate group to post this in. I‚Äôm working as a data engineer for a gaming company in Berlin. I don‚Äôt have a proper team. Our CTO wrote a custom data pipeline in C sharp years ago.  I was expected to take responsibility maintaining, improving, optimising the data pipeline, integrate a couple APIs, ingress data from marketing tools and ad network as well as reporting on looker studio for BI. I managed to do this pretty quickly after joining and am doing pretty well. However , since I do not have a team there is no senior to look up to, no team to discuss ideas with, no plans to\nintegrate data tools like snowflake or airflow , I feel\n1. There is no one I can interact with who understands my work at my workplace \n2. I am unable to expand practical knowledge in data engineering since we not introducing any new tools \n3. Progression is unclear e.g what qualifies me for a senior data engineer role at the studio\n3. It‚Äôs pretty quiet and sad at work without a team.</p>\n\n<p>For those date engineers who are a solo person team, how do you cope with all this ? Is it advisable to start looking for a new job ? </p>\n\n<p>I have started learning airflow and snowflake on my own as it might help me switch jobs later on </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imicne', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='areeba_k84'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imicne/need_advice_from_solosingle_member_team_data/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imicne/need_advice_from_solosingle_member_team_data/', 'subreddit_subscribers': 254039, 'created_utc': 1739224669.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.387+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "What's the best approach here?\n\nWe're syncing lead data from Snowflake into an external system, but the external system counts all fields in the payload in every refresh, even if only one field value is updated. This leads to unnecessary data point usage!\n\nSo, how we create dynamic schema for every job?\n", 'author_fullname': 't2_qicl50lv', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Delta mechanism', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imutvq', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739266229.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>What&#39;s the best approach here?</p>\n\n<p>We&#39;re syncing lead data from Snowflake into an external system, but the external system counts all fields in the payload in every refresh, even if only one field value is updated. This leads to unnecessary data point usage!</p>\n\n<p>So, how we create dynamic schema for every job?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1imutvq', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Huggable_Guy'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imutvq/delta_mechanism/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imutvq/delta_mechanism/', 'subreddit_subscribers': 254039, 'created_utc': 1739266229.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.387+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Curious what folks here think about this. YC‚Äôs been talking a lot about B2A (Business-to-Agent) companies, and it got me thinking. For years, analytics has been all about humans, right? Dashboards, reports, charts. stuff designed to help people make decisions. But what happens when humans aren‚Äôt the ones making the decisions anymore? like agents running workflow automation\n\nAre we maybe on the edge of a shift from B2B/B2C to B2A? In this world, AI agents become the main consumers of data, not people. So, do we even need dashboards and reports anymore? If agents can process and act on data in real-time, what‚Äôs the point of traditional BI tools? They‚Äôre built for human schedules like daily, weekly check-in.... but agents operate instantly. is the future more about machine-to-machine analytics? Would love to hear what others think.\n\ni wrote some thoughts on [https://blog.structuredlabs.com/p/b2a-the-future-of-analytics-isnt](https://blog.structuredlabs.com/p/b2a-the-future-of-analytics-isnt)', 'author_fullname': 't2_1bm2qxyatc', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'B2A analytics looks different', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imk1eu', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739228976.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Curious what folks here think about this. YC‚Äôs been talking a lot about B2A (Business-to-Agent) companies, and it got me thinking. For years, analytics has been all about humans, right? Dashboards, reports, charts. stuff designed to help people make decisions. But what happens when humans aren‚Äôt the ones making the decisions anymore? like agents running workflow automation</p>\n\n<p>Are we maybe on the edge of a shift from B2B/B2C to B2A? In this world, AI agents become the main consumers of data, not people. So, do we even need dashboards and reports anymore? If agents can process and act on data in real-time, what‚Äôs the point of traditional BI tools? They‚Äôre built for human schedules like daily, weekly check-in.... but agents operate instantly. is the future more about machine-to-machine analytics? Would love to hear what others think.</p>\n\n<p>i wrote some thoughts on <a href="https://blog.structuredlabs.com/p/b2a-the-future-of-analytics-isnt">https://blog.structuredlabs.com/p/b2a-the-future-of-analytics-isnt</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/pC2CVOGAVEUs8linMMMZf-XAE0A4y64dpldFSAeU2-U.jpg?auto=webp&s=24bb9ac725d1d0db4cb24d7f3b514c36e941c681', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/pC2CVOGAVEUs8linMMMZf-XAE0A4y64dpldFSAeU2-U.jpg?width=108&crop=smart&auto=webp&s=82ed3d5f403fd1ae45b8b745da5ca4084386fbb9', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/pC2CVOGAVEUs8linMMMZf-XAE0A4y64dpldFSAeU2-U.jpg?width=216&crop=smart&auto=webp&s=c3755996b3c9b2ddbb88b05c7001cca4f0189a96', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/pC2CVOGAVEUs8linMMMZf-XAE0A4y64dpldFSAeU2-U.jpg?width=320&crop=smart&auto=webp&s=7b9963bcec60e65545432c7a46cf8165f2d043b4', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/pC2CVOGAVEUs8linMMMZf-XAE0A4y64dpldFSAeU2-U.jpg?width=640&crop=smart&auto=webp&s=17d766753b0250cb51d4695771fd08a5d7fbb6b5', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/pC2CVOGAVEUs8linMMMZf-XAE0A4y64dpldFSAeU2-U.jpg?width=960&crop=smart&auto=webp&s=2d347bef0abb0a5b8ed3c5fe85b490c2126c4466', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/pC2CVOGAVEUs8linMMMZf-XAE0A4y64dpldFSAeU2-U.jpg?width=1080&crop=smart&auto=webp&s=d3c611f3f728ed60d227f0c0cb19c97d423a2e3d', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'UcIrG4o1kqp_s4GWgH14JSqwqRPrhxp_rXoUcxUdBZ4'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1imk1eu', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Amrutha-Structured'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imk1eu/b2a_analytics_looks_different/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imk1eu/b2a_analytics_looks_different/', 'subreddit_subscribers': 254039, 'created_utc': 1739228976.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.387+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hey there Data Engs,\n\nI need some testimony on how secrets managements are handled with Dagster ?\n\nAny one have a good experience with this ?\n\n  \nI handled Vault integration by creating a CLI wrapper (yeah i know) around ***bao*** commands, which I declare in [definitions.py](https://docs.dagster.io/api/python-api/definitions) and use to inject secrets into Dagster resources that needs them.\n\nI'm pretty sure this isn't a great solution, especially since the main thread doesn't block during the OIDC callback, causing Dagster resources to fail initialization. (i'll not go into much detail, this isnt a debug post)\n\nI also tried integrating the [hvac ](https://pypi.org/project/hvac/)client directly, but ran into so many issues that I fell back to the CLI wrapper approach.\n\nAnd, there is this : [https://dagster.io/integrations/dagster-hashicorp](https://dagster.io/integrations/dagster-hashicorp)\n\nBut I dont need my secrets into my assets ... I need them into my resources (shared between assets)\n\nI am missing something ...\n\nAm I supposed to just write an initialization script that fetches secrets and stores them in environment variables? That seems questionable from a security perspective.\n\nWhat you gud Data Engs have done to handle secrets in Dagster ?", 'author_fullname': 't2_bej8rl31', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Dagster with a Hashicorp Vault (OpenBao) - what are the best practices ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1img35g', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739219108.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey there Data Engs,</p>\n\n<p>I need some testimony on how secrets managements are handled with Dagster ?</p>\n\n<p>Any one have a good experience with this ?</p>\n\n<p>I handled Vault integration by creating a CLI wrapper (yeah i know) around <strong><em>bao</em></strong> commands, which I declare in <a href="https://docs.dagster.io/api/python-api/definitions">definitions.py</a> and use to inject secrets into Dagster resources that needs them.</p>\n\n<p>I&#39;m pretty sure this isn&#39;t a great solution, especially since the main thread doesn&#39;t block during the OIDC callback, causing Dagster resources to fail initialization. (i&#39;ll not go into much detail, this isnt a debug post)</p>\n\n<p>I also tried integrating the <a href="https://pypi.org/project/hvac/">hvac </a>client directly, but ran into so many issues that I fell back to the CLI wrapper approach.</p>\n\n<p>And, there is this : <a href="https://dagster.io/integrations/dagster-hashicorp">https://dagster.io/integrations/dagster-hashicorp</a></p>\n\n<p>But I dont need my secrets into my assets ... I need them into my resources (shared between assets)</p>\n\n<p>I am missing something ...</p>\n\n<p>Am I supposed to just write an initialization script that fetches secrets and stores them in environment variables? That seems questionable from a security perspective.</p>\n\n<p>What you gud Data Engs have done to handle secrets in Dagster ?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/Vx6RjkfF1dTDbMGaBckvcEiY0XZHEXffZEOZZenRIGM.jpg?auto=webp&s=bbb6da4603c475a6011ae0ddbf7ff8f0de1d98fc', 'width': 2400, 'height': 1260}, 'resolutions': [{'url': 'https://external-preview.redd.it/Vx6RjkfF1dTDbMGaBckvcEiY0XZHEXffZEOZZenRIGM.jpg?width=108&crop=smart&auto=webp&s=a94c4d82c55436e19f93055e32ee75e0ab378400', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/Vx6RjkfF1dTDbMGaBckvcEiY0XZHEXffZEOZZenRIGM.jpg?width=216&crop=smart&auto=webp&s=844bc5dd5be3d4bf5662d6294ebe0233e81b6864', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/Vx6RjkfF1dTDbMGaBckvcEiY0XZHEXffZEOZZenRIGM.jpg?width=320&crop=smart&auto=webp&s=470f36192b3a280c1693a78dc08856999dd2a4c6', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/Vx6RjkfF1dTDbMGaBckvcEiY0XZHEXffZEOZZenRIGM.jpg?width=640&crop=smart&auto=webp&s=7286cb924a1a6b9fddbcb703739a9da6c52b272a', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/Vx6RjkfF1dTDbMGaBckvcEiY0XZHEXffZEOZZenRIGM.jpg?width=960&crop=smart&auto=webp&s=1c3bee67a179b0b28fad440fca4dfe9ccb67f73f', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/Vx6RjkfF1dTDbMGaBckvcEiY0XZHEXffZEOZZenRIGM.jpg?width=1080&crop=smart&auto=webp&s=53ed15c4b4df3f3b0cd4126f74f895bc4f612fb7', 'width': 1080, 'height': 567}], 'variants': {}, 'id': 'VPqWqO0DS_P_--Yl6hRNgHatjgrQ6592VBmMHQn_4Ws'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1img35g', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='fixmyanxiety'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1img35g/dagster_with_a_hashicorp_vault_openbao_what_are/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1img35g/dagster_with_a_hashicorp_vault_openbao_what_are/', 'subreddit_subscribers': 254039, 'created_utc': 1739219108.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.387+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "GitHub: [github.com/datazip-inc/olake](http://github.com/datazip-inc/olake) (130+ ‚≠ê  and growing fast)  \n  \nWe made this mistake in our first product by building a lot of connectors and learnt the hard way to pick a pressing pain point and build a world class solution for it (we ar trying atleast)\n\ntry it out - [https://olake.io/docs/getting-started](https://olake.io/docs/getting-started) \\[CLI based, UI under development\\]\n\n**Who is it for?**\n\nWe built this for data engineers and engineers teams struggling with:\n\n1. Debezium + Kafka setup and that 16MB per document size limitation of Debezium when working with mongoDB. Its Debezium free.\n2. lost cursors management during the CDC process, with no way left other than to resync the entire data.\n3. sync running for hours and hours and you have no visibility into what's happening under the hood. Limited visibility (the sync logs, completion time, which table is being replicated, etc).\n4. complexity of setting with Debezium + Kafka pipeline or other solutions.\n5. present ETL tools are very generic and not optimised to sync DB\xa0 data to a\xa0 lakehouse and handling all the associated complexities (metadata + schema management)\n6. knowing from where to restart the sync. Here, features like resumable syncs + visibility of exactly where the sync paused + stored cursor token you get with OLake\n\nDocs & Quickstart: [olake.io/docs](http://olake.io/docs)\n\nWe‚Äôd love to hear your thoughts, contributions, and any feedback as you try OLake in your projects.\n\nWe are calling out for contributors, OLake is an Apache 2.0 license maintained by Datazip.", 'author_fullname': 't2_9vpliu5j', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Building OLake -  Open source database to Iceberg data replication ETL tool, Apache 2 license', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imdjzc', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Open Source', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739213096.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>GitHub: <a href="http://github.com/datazip-inc/olake">github.com/datazip-inc/olake</a> (130+ ‚≠ê  and growing fast)  </p>\n\n<p>We made this mistake in our first product by building a lot of connectors and learnt the hard way to pick a pressing pain point and build a world class solution for it (we ar trying atleast)</p>\n\n<p>try it out - <a href="https://olake.io/docs/getting-started">https://olake.io/docs/getting-started</a> [CLI based, UI under development]</p>\n\n<p><strong>Who is it for?</strong></p>\n\n<p>We built this for data engineers and engineers teams struggling with:</p>\n\n<ol>\n<li>Debezium + Kafka setup and that 16MB per document size limitation of Debezium when working with mongoDB. Its Debezium free.</li>\n<li>lost cursors management during the CDC process, with no way left other than to resync the entire data.</li>\n<li>sync running for hours and hours and you have no visibility into what&#39;s happening under the hood. Limited visibility (the sync logs, completion time, which table is being replicated, etc).</li>\n<li>complexity of setting with Debezium + Kafka pipeline or other solutions.</li>\n<li>present ETL tools are very generic and not optimised to sync DB\xa0 data to a\xa0 lakehouse and handling all the associated complexities (metadata + schema management)</li>\n<li>knowing from where to restart the sync. Here, features like resumable syncs + visibility of exactly where the sync paused + stored cursor token you get with OLake</li>\n</ol>\n\n<p>Docs &amp; Quickstart: <a href="http://olake.io/docs">olake.io/docs</a></p>\n\n<p>We‚Äôd love to hear your thoughts, contributions, and any feedback as you try OLake in your projects.</p>\n\n<p>We are calling out for contributors, OLake is an Apache 2.0 license maintained by Datazip.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/yGcC9a1fQrSs6Qdc_QquF84BQSta4D7vZBdgJyvMJxU.jpg?auto=webp&s=89e55b31c5e8150937a83f62580f697899f97099', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/yGcC9a1fQrSs6Qdc_QquF84BQSta4D7vZBdgJyvMJxU.jpg?width=108&crop=smart&auto=webp&s=1577a8de5ce3b7b49e1f968fd3d6e6d924389ccb', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/yGcC9a1fQrSs6Qdc_QquF84BQSta4D7vZBdgJyvMJxU.jpg?width=216&crop=smart&auto=webp&s=5ad71d915bfea4e8e3e2ef2d747ecba151b528a9', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/yGcC9a1fQrSs6Qdc_QquF84BQSta4D7vZBdgJyvMJxU.jpg?width=320&crop=smart&auto=webp&s=ef6c25d857512e073d762c4358fbae415402eddd', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/yGcC9a1fQrSs6Qdc_QquF84BQSta4D7vZBdgJyvMJxU.jpg?width=640&crop=smart&auto=webp&s=15abf7783fd7dbc98592c147a63c3c917df21d11', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/yGcC9a1fQrSs6Qdc_QquF84BQSta4D7vZBdgJyvMJxU.jpg?width=960&crop=smart&auto=webp&s=c7c838ef52a1587ab214e37921a0c20c8c351ccc', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/yGcC9a1fQrSs6Qdc_QquF84BQSta4D7vZBdgJyvMJxU.jpg?width=1080&crop=smart&auto=webp&s=34747d2c0247b116122ca162c49eba990597f0c0', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'FjAlcS-FGlGU1J34O_gHkzDiqWtiTvPdpUAIwc6ZyP8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '3957ca64-3440-11ed-8329-2aa6ad243a59', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#005ba1', 'id': '1imdjzc', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='zzriyansh'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imdjzc/building_olake_open_source_database_to_iceberg/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imdjzc/building_olake_open_source_database_to_iceberg/', 'subreddit_subscribers': 254039, 'created_utc': 1739213096.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.388+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Found this info graph on DE on linkedin. How relevant is this? Is Hadoop actually required?\n\nhttps://preview.redd.it/wpelu1fv8cie1.png?width=800&format=png&auto=webp&s=ed0183dceb46d0f81d0b44da252f8e0438f35579\n\n', 'author_fullname': 't2_rr6r6b8v', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How relevant is this data engineering Infograph?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'wpelu1fv8cie1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 149, 'x': 108, 'u': 'https://preview.redd.it/wpelu1fv8cie1.png?width=108&crop=smart&auto=webp&s=806991373d9e3da42c47c6c9f78b2b877f730aa1'}, {'y': 299, 'x': 216, 'u': 'https://preview.redd.it/wpelu1fv8cie1.png?width=216&crop=smart&auto=webp&s=f43e5ba195f370ae377d126d1eee8fc4788b760c'}, {'y': 444, 'x': 320, 'u': 'https://preview.redd.it/wpelu1fv8cie1.png?width=320&crop=smart&auto=webp&s=ce6049ad2ccf105ca611889a3724c34402560ee9'}, {'y': 888, 'x': 640, 'u': 'https://preview.redd.it/wpelu1fv8cie1.png?width=640&crop=smart&auto=webp&s=ac15ad242abe2ff421f7ee52184f3a3aa9a20c45'}], 's': {'y': 1111, 'x': 800, 'u': 'https://preview.redd.it/wpelu1fv8cie1.png?width=800&format=png&auto=webp&s=ed0183dceb46d0f81d0b44da252f8e0438f35579'}, 'id': 'wpelu1fv8cie1'}}, 'name': 't3_1ima57v', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/gijje2y1RCstZrKDm6z7qdfgTexKV5Do96RC2o6MrPM.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739204923.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Found this info graph on DE on linkedin. How relevant is this? Is Hadoop actually required?</p>\n\n<p><a href="https://preview.redd.it/wpelu1fv8cie1.png?width=800&amp;format=png&amp;auto=webp&amp;s=ed0183dceb46d0f81d0b44da252f8e0438f35579">https://preview.redd.it/wpelu1fv8cie1.png?width=800&amp;format=png&amp;auto=webp&amp;s=ed0183dceb46d0f81d0b44da252f8e0438f35579</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1ima57v', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='_areebpasha'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1ima57v/how_relevant_is_this_data_engineering_infograph/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ima57v/how_relevant_is_this_data_engineering_infograph/', 'subreddit_subscribers': 254039, 'created_utc': 1739204923.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.388+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi all,\n\nLooking for a little bit of advice as I try to work out where to go next in my career. About 3 years ago I did a career change into data analytics. Since then I've become an intermediate to advanced Power BI developer in a very good medical device company. \n\nI'm wondering where to go next from here. I feel like I've hit my ceiling in the world of Power BI (financially and intellectually), and like the idea of transitioning to data engineering in some way. \n\nA mentor of mine told me to study Databricks as this would be a key tool to understand (in my current company and if I went to another company). Before I dive headlong into DB, I wanted to ask if this is what experienced engineers would recommend? Thanks!", 'author_fullname': 't2_afw98pdez', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Transitioning from analytics into engineering (Databricks)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imhxb9', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.6, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739223622.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi all,</p>\n\n<p>Looking for a little bit of advice as I try to work out where to go next in my career. About 3 years ago I did a career change into data analytics. Since then I&#39;ve become an intermediate to advanced Power BI developer in a very good medical device company. </p>\n\n<p>I&#39;m wondering where to go next from here. I feel like I&#39;ve hit my ceiling in the world of Power BI (financially and intellectually), and like the idea of transitioning to data engineering in some way. </p>\n\n<p>A mentor of mine told me to study Databricks as this would be a key tool to understand (in my current company and if I went to another company). Before I dive headlong into DB, I wanted to ask if this is what experienced engineers would recommend? Thanks!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imhxb9', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='custerdomecreative'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imhxb9/transitioning_from_analytics_into_engineering/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imhxb9/transitioning_from_analytics_into_engineering/', 'subreddit_subscribers': 254039, 'created_utc': 1739223622.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.388+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I have 3 years of experience in data engineering and have been improving technically tremendously throughout the journey. I put my head down to resolve technical and business problems and celebrate all the achievements I have made. My good work is recognized by our business partners but I got a sense that it is not enough for me to advance into a more senior role. I am a quiet person; even though I put in a lot of effort, I think my manager expects more. \n\nI don\'t want to leave this company just yet. I acknowledge that every job, including a technical one, involves human factors - you must be seen and liked by others for a promotion. This will stay true even if I move to another company. From your experience, in order to move into a senior DE role, how should one improve from the "people" perspectives? How to improve your publicity / influence to convince your manager that you are ready?', 'author_fullname': 't2_373qt8fr', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Advancing into a senior role', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imb5ey', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.57, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1739213259.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739207351.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I have 3 years of experience in data engineering and have been improving technically tremendously throughout the journey. I put my head down to resolve technical and business problems and celebrate all the achievements I have made. My good work is recognized by our business partners but I got a sense that it is not enough for me to advance into a more senior role. I am a quiet person; even though I put in a lot of effort, I think my manager expects more. </p>\n\n<p>I don&#39;t want to leave this company just yet. I acknowledge that every job, including a technical one, involves human factors - you must be seen and liked by others for a promotion. This will stay true even if I move to another company. From your experience, in order to move into a senior DE role, how should one improve from the &quot;people&quot; perspectives? How to improve your publicity / influence to convince your manager that you are ready?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imb5ey', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='goatsyelllikehuman'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imb5ey/advancing_into_a_senior_role/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imb5ey/advancing_into_a_senior_role/', 'subreddit_subscribers': 254039, 'created_utc': 1739207351.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.389+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I‚Äôm trying to create connection to r12db from databricks by this sample code\n\njdbc_url = "jdbc:oracle:thin:@<hostname>:<port>:<service_name>"\n\nproperties = {\n    "user": "<oracle_user>",\n    "password": "<oracle_password>",\n    "driver": "oracle.jdbc.OracleDriver"\n}\n\n# Reading data from Oracle to a Spark DataFrame\ndf = spark.read.jdbc(url=jdbc_url, table="<your_table>", properties=properties)\n\n# Show the data\ndf.show()\n Im getting this error 10 Error: The Network Adapter could not establish the connection but credential is correct only help me pls this is urgent I‚Äôm new to this\n', 'author_fullname': 't2_9vloilxi', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Databricks connection to r12db', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1ima3fj', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739204798.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I‚Äôm trying to create connection to r12db from databricks by this sample code</p>\n\n<p>jdbc_url = &quot;jdbc:oracle:thin:@&lt;hostname&gt;:&lt;port&gt;:&lt;service_name&gt;&quot;</p>\n\n<p>properties = {\n    &quot;user&quot;: &quot;&lt;oracle_user&gt;&quot;,\n    &quot;password&quot;: &quot;&lt;oracle_password&gt;&quot;,\n    &quot;driver&quot;: &quot;oracle.jdbc.OracleDriver&quot;\n}</p>\n\n<h1>Reading data from Oracle to a Spark DataFrame</h1>\n\n<p>df = spark.read.jdbc(url=jdbc_url, table=&quot;&lt;your_table&gt;&quot;, properties=properties)</p>\n\n<h1>Show the data</h1>\n\n<p>df.show()\n Im getting this error 10 Error: The Network Adapter could not establish the connection but credential is correct only help me pls this is urgent I‚Äôm new to this</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1ima3fj', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='robin_son12'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1ima3fj/databricks_connection_to_r12db/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ima3fj/databricks_connection_to_r12db/', 'subreddit_subscribers': 254039, 'created_utc': 1739204798.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.389+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Quick walkthrough I made for creating a default ipython profile and configuring it to always show all columns when working with pandas. \n\nBonus: You can also set default imports. I wouldn't actually do this as I like to be explicit with things like that, but it's another tool in your tool belt.   \n[https://www.youtube.com/watch?v=agKUttg4doM](https://www.youtube.com/watch?v=agKUttg4doM)", 'author_fullname': 't2_vacamarkw', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Setting Pandas to Show All Columns by Default in a Notebook', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1im6t4x', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.58, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739196221.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Quick walkthrough I made for creating a default ipython profile and configuring it to always show all columns when working with pandas. </p>\n\n<p>Bonus: You can also set default imports. I wouldn&#39;t actually do this as I like to be explicit with things like that, but it&#39;s another tool in your tool belt.<br/>\n<a href="https://www.youtube.com/watch?v=agKUttg4doM">https://www.youtube.com/watch?v=agKUttg4doM</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/01bT2y4ct31g2KlvmDfLgJRZEprSEiALoS_A_2MvCUc.jpg?auto=webp&s=61afb3f8c9a602156047043c2c41f366d2d5a0bb', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/01bT2y4ct31g2KlvmDfLgJRZEprSEiALoS_A_2MvCUc.jpg?width=108&crop=smart&auto=webp&s=61dea00a0990c98d44b23084c0fb59a19279a786', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/01bT2y4ct31g2KlvmDfLgJRZEprSEiALoS_A_2MvCUc.jpg?width=216&crop=smart&auto=webp&s=0168bfa160d9b2ad53075d5e85ee26adb7eca578', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/01bT2y4ct31g2KlvmDfLgJRZEprSEiALoS_A_2MvCUc.jpg?width=320&crop=smart&auto=webp&s=489ef4e90c173b4bd30e50975ad263b0bc7c13f4', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'zqRMmi2DstDPTPsvnvEOkmXdxow81kvsw3GDVJkKjpg'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1im6t4x', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='DataSling3r'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1im6t4x/setting_pandas_to_show_all_columns_by_default_in/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1im6t4x/setting_pandas_to_show_all_columns_by_default_in/', 'subreddit_subscribers': 254039, 'created_utc': 1739196221.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.389+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hello Community,\n\nI\'m in my last semesters of grad school, and graduating sucks if you don\'t have a job offer in hand. I\'m applying to 30+ jobs daily‚Äîsometimes even more‚Äîbut I still haven\'t managed to convert any openings into a callback.\n\nIt might not sound too bad when you read it, but many of you have likely faced the same problem in your career. What steps did you take? In addition to the actions I\'m actively following:\n\n* Tailoring CV/ Res>ume\n* Applying ASAP (within the first 30 minutes)\n* Reaching out to people in the same role or higher for insights or potential referrals\n* Contacting hiring managers/recruiters\n* Scouting my existing network for people who are "Actively Hiring"\n* Meeting new people at events/hackathons\n* Attending career fairs\n\nI\'ve been doing these seven steps endlessly, yet nothing changes‚ÄîI remain stuck in the loop. The best outcome so far was a call from Amazon Robotics for a Co-Op Data Scientist position for Spring 2025. Honestly, that wasn‚Äôt my best interv>iew‚ÄîI messed up big time.\n\nSince then, I\'ve added an 8th step: refreshing all the fundamentals and practicing SQL, DSA, Data Engineering, and Data Science concepts, with some GEN AI projects on the side.\n\nI do have on paper 1.8 years of Data Engineering experience handling multiple clients like J&J, Walmart, and Yamaha Motors.', 'author_fullname': 't2_wyi497rjk', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Career Help', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imn0vf', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739237443.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello Community,</p>\n\n<p>I&#39;m in my last semesters of grad school, and graduating sucks if you don&#39;t have a job offer in hand. I&#39;m applying to 30+ jobs daily‚Äîsometimes even more‚Äîbut I still haven&#39;t managed to convert any openings into a callback.</p>\n\n<p>It might not sound too bad when you read it, but many of you have likely faced the same problem in your career. What steps did you take? In addition to the actions I&#39;m actively following:</p>\n\n<ul>\n<li>Tailoring CV/ Res&gt;ume</li>\n<li>Applying ASAP (within the first 30 minutes)</li>\n<li>Reaching out to people in the same role or higher for insights or potential referrals</li>\n<li>Contacting hiring managers/recruiters</li>\n<li>Scouting my existing network for people who are &quot;Actively Hiring&quot;</li>\n<li>Meeting new people at events/hackathons</li>\n<li>Attending career fairs</li>\n</ul>\n\n<p>I&#39;ve been doing these seven steps endlessly, yet nothing changes‚ÄîI remain stuck in the loop. The best outcome so far was a call from Amazon Robotics for a Co-Op Data Scientist position for Spring 2025. Honestly, that wasn‚Äôt my best interv&gt;iew‚ÄîI messed up big time.</p>\n\n<p>Since then, I&#39;ve added an 8th step: refreshing all the fundamentals and practicing SQL, DSA, Data Engineering, and Data Science concepts, with some GEN AI projects on the side.</p>\n\n<p>I do have on paper 1.8 years of Data Engineering experience handling multiple clients like J&amp;J, Walmart, and Yamaha Motors.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imn0vf', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Inner-Extreme-4411'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imn0vf/career_help/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imn0vf/career_help/', 'subreddit_subscribers': 254039, 'created_utc': 1739237443.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.389+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Has anyone taken the Tower hacker rank on pandas and python? 10 questions in 90 mins?', 'author_fullname': 't2_clbb2rwp9', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Pandas hackerrank', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1im94v9', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739202433.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Has anyone taken the Tower hacker rank on pandas and python? 10 questions in 90 mins?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1im94v9', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='IndividualWaltz4547'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1im94v9/pandas_hackerrank/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1im94v9/pandas_hackerrank/', 'subreddit_subscribers': 254039, 'created_utc': 1739202433.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.390+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hello Everyone,\n\nI just came across this post on LinkedIn by Cristian Scutaru about Zach Wilson and wanted to share on DE community.\n\n  \nI enrolled into Zach's free bootcamp back in November 2024 but could never go past the 1st week due to personal commitments. I heard it's very intense and is mostly for people at intermediate level and not for beginners.\n\n[https://cristian-70480.medium.com/hypocrisy-of-the-rich-or-the-case-of-zach-wilson-b70996c72039](https://cristian-70480.medium.com/hypocrisy-of-the-rich-or-the-case-of-zach-wilson-b70996c72039)", 'author_fullname': 't2_j3otb4izk', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Cristian Scutaru (Snowflake expert) article on Medium about Zach Wilson Character', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imihcf', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.4, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739224978.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello Everyone,</p>\n\n<p>I just came across this post on LinkedIn by Cristian Scutaru about Zach Wilson and wanted to share on DE community.</p>\n\n<p>I enrolled into Zach&#39;s free bootcamp back in November 2024 but could never go past the 1st week due to personal commitments. I heard it&#39;s very intense and is mostly for people at intermediate level and not for beginners.</p>\n\n<p><a href="https://cristian-70480.medium.com/hypocrisy-of-the-rich-or-the-case-of-zach-wilson-b70996c72039">https://cristian-70480.medium.com/hypocrisy-of-the-rich-or-the-case-of-zach-wilson-b70996c72039</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/rpFRGY07Z_YlrDmYAFBu-IkyWSqWeX7AWqalOvxmlqI.jpg?auto=webp&s=853f4d00b32a815400686938b80368f1a9c1d21f', 'width': 1200, 'height': 848}, 'resolutions': [{'url': 'https://external-preview.redd.it/rpFRGY07Z_YlrDmYAFBu-IkyWSqWeX7AWqalOvxmlqI.jpg?width=108&crop=smart&auto=webp&s=be80355127e628da60db5cd34d45fda76617ec8b', 'width': 108, 'height': 76}, {'url': 'https://external-preview.redd.it/rpFRGY07Z_YlrDmYAFBu-IkyWSqWeX7AWqalOvxmlqI.jpg?width=216&crop=smart&auto=webp&s=6deea13ca563b121290014a9552cca06665b410c', 'width': 216, 'height': 152}, {'url': 'https://external-preview.redd.it/rpFRGY07Z_YlrDmYAFBu-IkyWSqWeX7AWqalOvxmlqI.jpg?width=320&crop=smart&auto=webp&s=52154d577f0903dbdbbabb1e1a49d39c24f9b2b1', 'width': 320, 'height': 226}, {'url': 'https://external-preview.redd.it/rpFRGY07Z_YlrDmYAFBu-IkyWSqWeX7AWqalOvxmlqI.jpg?width=640&crop=smart&auto=webp&s=61cff1c0110c4d7572e064153226408dd262494a', 'width': 640, 'height': 452}, {'url': 'https://external-preview.redd.it/rpFRGY07Z_YlrDmYAFBu-IkyWSqWeX7AWqalOvxmlqI.jpg?width=960&crop=smart&auto=webp&s=96bd3892050c14cb7c804dbb0844aacef52a9dc8', 'width': 960, 'height': 678}, {'url': 'https://external-preview.redd.it/rpFRGY07Z_YlrDmYAFBu-IkyWSqWeX7AWqalOvxmlqI.jpg?width=1080&crop=smart&auto=webp&s=1b69bcfbe2337e45bc3100fc95c22335e3910c60', 'width': 1080, 'height': 763}], 'variants': {}, 'id': 'WX3uVjHlzyoqKB7s7QPQCuXkNI7U2y52QuBv-Q2Z4IA'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imihcf', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='69odysseus'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imihcf/cristian_scutaru_snowflake_expert_article_on/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imihcf/cristian_scutaru_snowflake_expert_article_on/', 'subreddit_subscribers': 254039, 'created_utc': 1739224978.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.390+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi everyone, please be easy on me, because what I am going to ask may sound so stereotypical and straight out folly, haha it may not even exist!\n\nI am new to this field, and I want to pursue a specific type of data processing, something that I now realise I have always been skirting around in my day-to-day life, not knowing a career could be made out of it. I am in no way gifted with the computer, but I have always loved organising and being detail-oriented in my day-to-day life. I have always been interested in creating an application that acts as a command f (mac user) across browsers to find specific info. Writing this, I realise that it sounds like I am talking about chat GPT... but what I want to know is what type of career/degree my interest falls under. \n\nThank you!!', 'author_fullname': 't2_cm58pfvs', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': "I want to get into data processing, but I don't know what I should to do", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imhcwx', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.4, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739222223.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi everyone, please be easy on me, because what I am going to ask may sound so stereotypical and straight out folly, haha it may not even exist!</p>\n\n<p>I am new to this field, and I want to pursue a specific type of data processing, something that I now realise I have always been skirting around in my day-to-day life, not knowing a career could be made out of it. I am in no way gifted with the computer, but I have always loved organising and being detail-oriented in my day-to-day life. I have always been interested in creating an application that acts as a command f (mac user) across browsers to find specific info. Writing this, I realise that it sounds like I am talking about chat GPT... but what I want to know is what type of career/degree my interest falls under. </p>\n\n<p>Thank you!!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imhcwx', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Melo-nie'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imhcwx/i_want_to_get_into_data_processing_but_i_dont/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imhcwx/i_want_to_get_into_data_processing_but_i_dont/', 'subreddit_subscribers': 254039, 'created_utc': 1739222223.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.390+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I have a master's in Data Science and am planning to transition into Data Engineering. I have a basic understanding of how things work, but I want to learn more about the roles, projects, and responsibilities of a Data Engineer. Specifically, I‚Äôd like to understand the ETL process ,what sources data is extracted from, how it is loaded, and whether a Data Engineer is also responsible for analysis or just ETL. I apologize for my somewhat unstructured question. I just want to understand how things work from scratch in the industry so I can learn and prepare myself for the role.", 'author_fullname': 't2_26svyp8p', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What are responsibilities of a data engineer?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imrgny', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.44, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739251897.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I have a master&#39;s in Data Science and am planning to transition into Data Engineering. I have a basic understanding of how things work, but I want to learn more about the roles, projects, and responsibilities of a Data Engineer. Specifically, I‚Äôd like to understand the ETL process ,what sources data is extracted from, how it is loaded, and whether a Data Engineer is also responsible for analysis or just ETL. I apologize for my somewhat unstructured question. I just want to understand how things work from scratch in the industry so I can learn and prepare myself for the role.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imrgny', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='itachiseshank'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imrgny/what_are_responsibilities_of_a_data_engineer/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imrgny/what_are_responsibilities_of_a_data_engineer/', 'subreddit_subscribers': 254039, 'created_utc': 1739251897.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.390+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'How useful is it to learn Palantir Foundry?', 'author_fullname': 't2_pjy9r4qn', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Palantir Foundry', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imqc0k', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.33, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739247981.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>How useful is it to learn Palantir Foundry?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1imqc0k', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Lucky_Fortune_Sun'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imqc0k/palantir_foundry/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imqc0k/palantir_foundry/', 'subreddit_subscribers': 254039, 'created_utc': 1739247981.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.390+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hey everyone, I‚Äôve been really busy these past few months and wasn‚Äôt able to watch the lecture videos. Does anyone have them downloaded? I‚Äôd really appreciate it.   \n  \nThanks in advance!', 'author_fullname': 't2_jksyqc9k', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Was anyone able to download Zach Wilson Data Engineering Free Bootcamp videos?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imb0o5', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.29, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739207037.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey everyone, I‚Äôve been really busy these past few months and wasn‚Äôt able to watch the lecture videos. Does anyone have them downloaded? I‚Äôd really appreciate it.   </p>\n\n<p>Thanks in advance!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1imb0o5', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Acceptable_Wolf9893'), 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imb0o5/was_anyone_able_to_download_zach_wilson_data/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1imb0o5/was_anyone_able_to_download_zach_wilson_data/', 'subreddit_subscribers': 254039, 'created_utc': 1739207037.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.390+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Normalization is the key to making messy data useful. In my latest Substack post, I share lessons learned from working with user-generated content and the challenges of standardizing data. \n\nRead more: [https://stephenbgalla.substack.com/p/data](https://stephenbgalla.substack.com/p/data)', 'author_fullname': 't2_a0a8p54y', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data - The Devil Is In The Details', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1im9fhd', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.44, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1739203186.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Normalization is the key to making messy data useful. In my latest Substack post, I share lessons learned from working with user-generated content and the challenges of standardizing data. </p>\n\n<p>Read more: <a href="https://stephenbgalla.substack.com/p/data">https://stephenbgalla.substack.com/p/data</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/2GvSj3u_8I3tJf9cRNbLtJt7i7i2UsjsF11eqOKH2XI.jpg?auto=webp&s=e64035f9b4befa3241898c6232cd636474ddd561', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/2GvSj3u_8I3tJf9cRNbLtJt7i7i2UsjsF11eqOKH2XI.jpg?width=108&crop=smart&auto=webp&s=42c47cb248320ef730e69cbc7280c56abfdbd631', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/2GvSj3u_8I3tJf9cRNbLtJt7i7i2UsjsF11eqOKH2XI.jpg?width=216&crop=smart&auto=webp&s=591d1cc69224221ee9e27b0748d0d2c45f6fc7ea', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/2GvSj3u_8I3tJf9cRNbLtJt7i7i2UsjsF11eqOKH2XI.jpg?width=320&crop=smart&auto=webp&s=5c93975e0d8b3b0e13334201f75204d82b9c3a42', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/2GvSj3u_8I3tJf9cRNbLtJt7i7i2UsjsF11eqOKH2XI.jpg?width=640&crop=smart&auto=webp&s=999136ca8785ef26a72b9eb8cbdcde5f682a7cc9', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/2GvSj3u_8I3tJf9cRNbLtJt7i7i2UsjsF11eqOKH2XI.jpg?width=960&crop=smart&auto=webp&s=72000f7770c6b0043f6c07a3c0ad629df296576c', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/2GvSj3u_8I3tJf9cRNbLtJt7i7i2UsjsF11eqOKH2XI.jpg?width=1080&crop=smart&auto=webp&s=82bcf26cd152bed18090bd6dcf1868d1ba6f1135', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'BvXXOsWHr9YrD5HgjKw_7eVDcJZhqaJGZ0Xhobm7qRA'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1im9fhd', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='simply_unfinished'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1im9fhd/data_the_devil_is_in_the_details/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1im9fhd/data_the_devil_is_in_the_details/', 'subreddit_subscribers': 254039, 'created_utc': 1739203186.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.391+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff8f82a580>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I knew Elon was one of us. He understands the pain data engineer goes through daily . Just need his SQL skills updated ', 'author_fullname': 't2_2al86xis', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'I knew Elon was one of us. He understands the pain data engineer goes through daily', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1imdyl8', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.19, 'author_flair_background_color': None, 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Meme', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/ufDgrXaf5Qu2WtwlcZkNJ0ze2rCSUqYaMp3SCPSGq68.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'image', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1739214061.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I knew Elon was one of us. He understands the pain data engineer goes through daily . Just need his SQL skills updated </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/y7bxks9c0die1.jpeg', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://preview.redd.it/y7bxks9c0die1.jpeg?auto=webp&s=54354e9b4a64a0aee7090a9f7a51beac9b770f4c', 'width': 1170, 'height': 1231}, 'resolutions': [{'url': 'https://preview.redd.it/y7bxks9c0die1.jpeg?width=108&crop=smart&auto=webp&s=88cc4c5d2d32a7f17fa2ce469247ccd566060438', 'width': 108, 'height': 113}, {'url': 'https://preview.redd.it/y7bxks9c0die1.jpeg?width=216&crop=smart&auto=webp&s=d981c1d6bcc84883cdfe7b42641499281ef9f177', 'width': 216, 'height': 227}, {'url': 'https://preview.redd.it/y7bxks9c0die1.jpeg?width=320&crop=smart&auto=webp&s=dbb92c5c85dcb8aac9d10142dd18be6fc89affa5', 'width': 320, 'height': 336}, {'url': 'https://preview.redd.it/y7bxks9c0die1.jpeg?width=640&crop=smart&auto=webp&s=bffe6f2da0fe2897ac768c4a594b191b6cd4b7dd', 'width': 640, 'height': 673}, {'url': 'https://preview.redd.it/y7bxks9c0die1.jpeg?width=960&crop=smart&auto=webp&s=1e3b5b4ad5ce7787eccdaf1bc64c5dcf8db5e9cc', 'width': 960, 'height': 1010}, {'url': 'https://preview.redd.it/y7bxks9c0die1.jpeg?width=1080&crop=smart&auto=webp&s=61b06b1eda3305cf5abfe45b6a59756ae59d7ed7', 'width': 1080, 'height': 1136}], 'variants': {}, 'id': '1AZ1YJIVijRyubtTByy1smCx3gCoBwa2gJDfbbtDx6k'}], 'enabled': True}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1imdyl8', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='SmallBasil7'), 'discussion_type': None, 'num_comments': 16, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1imdyl8/i_knew_elon_was_one_of_us_he_understands_the_pain/', 'stickied': False, 'url': 'https://i.redd.it/y7bxks9c0die1.jpeg', 'subreddit_subscribers': 254039, 'created_utc': 1739214061.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2025-02-11T12:12:59.391+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-02-11T12:12:59.400+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-11T12:12:59.401+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=extract, run_id=manual__2025-02-11T12:12:56.666174+00:00, execution_date=20250211T121256, start_date=20250211T121258, end_date=20250211T121259
[2025-02-11T12:12:59.460+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-02-11T12:12:59.470+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-11T12:12:59.471+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
